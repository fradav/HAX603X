---
title: "Simulation"
format:
  html:
    out.width: 50%
filters:
  - shinylive
---


Dans ce chapitre on se demande comment simuler en pratique des variables aléatoires i.i.d. L'idée est de commencer par le cas de variables aléatoires de loi uniforme et d'en déduire les autres lois.


## Variables aléatoires uniformes

On rappelle qu'une variable aléatoire $U$ suit une loi uniforme sur $[0,1]$, noté $\mathcal{U}([0,1])$ si sa fonction de répartition $F_U$ est donnée par
$$
F_U(x)
=
\begin{cases}
    0, & \text{si }x < 0\,,        \\
    x, & \text{si }x \in [0,1]\,,  \\
    1, & \text{si }x > 1\,.        \\
\end{cases}
$$

```{python}
#| echo: false
#| label: fig-repartition-uniforme
#| fig-cap:
#|       - Fonction de répartition de la loi uniforme
import numpy as np
import scipy
import plotly.graph_objects as go

x = np.linspace(-3, 4, num=300)

fig = go.Figure()
fig.update_layout(
    template="simple_white",
    showlegend=True,
)

fig.add_trace(
              go.Scatter(
                  mode='lines',
                  line=dict(color='black', width=3),
                  x=x,
                  y=scipy.stats.uniform.cdf(x),
                  name=r'$F_U$'
         )
)

```

L'objectif est de simuler sur machine une suite $U_1, \ldots, U_n$  de variables aléatoires i.i.d. de loi $\mathcal{U}([0,1])$. Plusieurs problèmes apparaissent alors :

- Une machine est déterministe.
- Les nombres entre $0$ et $1$ donnés par la machine sont de la forme $k/2^p$, pour $k \in \{0, \ldots, 2^{p-1}\}$. On ne pourra donc jamais générer des nombres qui ne sont pas de cette forme.
- Vérifier qu'une suite est bien i.i.d. est un problème difficile.

::: {#def-PRNG}
## Générateur de nombres pseudo-aléatoires

<br>

Un **générateur de nombres pseudo-aléatoires** (&#127468;&#127463;: *Pseudo Random Number Generator*, PRNG), est un algorithme déterministe récursif qui renvoie une suite $U_1, \ldots, U_n$ dans $[0,1]$ qui a un "comportement similaire" à une suite i.i.d. de loi $\mathcal{U}([0,1])$.
Pour être plus rigoureux, ces nombres sont en fait des nombres entiers générés uniformément sur un certain interval. Dans un second une transformation simple permet d'obtenir des nombres flottants (&#127468;&#127463;: *floats*) entre 0 et 1.
:::


::: {.callout-note appearance="simple"}
## Pour aller plus loin
Parfois il est utile d'aller chercher dans le code source certaines information pour savoir comment les fonctions sont codées dans les packages que l'on utiliser. Par exemple, pour `numpy` que l'on utilise fréquement, on peut voir l'opération choisie ici: [Random: int -> float en `numpy`](https://github.com/numpy/numpy/blob/d50fc570a9e15ea4d8ec35add245d5d791fa4596/numpy/random/src/mt19937/randomkit.c#L479).
:::



Un tel algorithme se construit de la manière suivante :

1. On part d'une graine (&#127468;&#127463;: *seed*) $U_0$ qui détermine la première valeur de manière la plus arbitraire possible.
2. La procédure récursive s'écrit $U_{n+1} = f(U_n)$, où $f$ est une transformation déterministe, de sorte que $U_{n+1}$ est le plus indépendant possible de $U_1, \dots·, U_n$.


- La fonction $f$ est déterministe et prend ses valeurs dans un ensemble fini, donc l'algorithme est périodique. Le but est donc d'avoir la plus grande période possible.

- Notons qu'une fois que la graine est fixée, alors l'algorithme donne toujours les mêmes valeurs. Fixer la graine peut donc être très utile pour répéter des simulations dans des conditions identiques et ainsi repérer des erreurs.


::: {.callout-important appearance='default' icon="false"}
##  Exercice: bug ou feature?
Reprendre les widgets du chapitre [Théorèmes asymptotiques](th_asymptotique.qmd) et faites varier doucement le paramètre $p$ (de Bernoulli). Que constatez-vous? Proposer une explication potentielle.
:::

### Générateur congruentiel linéaire

La plupart des PRNG s'appuient sur des résultats arithmétiques. Un des plus connus est celui appelé Générateur congruentiel linéaire (&#127468;&#127463; Linear congruential generator, LCG).
Il est défini comme suit: on construit récursivement une suite d'entiers $X_i$ via la congruence
$$
  X_{n+1} = a X_n + b \quad \text{mod } m \enspace,
$$
où $a,b,m$ sont des entiers bien choisis pour que la suite obtenue ait de bonnes propriétés.
Il suffit alors de considérer $X_n/m$. Par exemple, la fonction ```rand``` sur ```scilab``` utilise cette congruence avec $m=2^{31}$, $a=843\; 314\; 861$, et $b=453\; 816\; 693$.

### Générateurs alternatifs
Les langages ```Python``` et ```R``` utilisent par défaut le générateur Mersenne-Twister qui s'appuie sur la multiplication vectorielle, mais d'autres générateurs sont aussi disponibles.
Ce générateur a pour période $m =2^{19937}-1$, nombre qu'on peut raisonnablement considérer comme grand.

Pour ```numpy``` la méthode par défaut est PCG64 (cf. [documentation de `numpy`](https://numpy.org/doc/stable/reference/random/bit_generators/pcg64.html)),
qui dispose de meilleures garanties statistiques (Voir le site [https://www.pcg-random.org](https://www.pcg-random.org/statistical-tests.html#id4) pour cela).


### Usage en `numpy`

On suppose désormais disposer d'un générateur pseudo-aléatoire sur $[0,1]$.
En `numpy` depuis la version 1.17, une bonne manière d'utiliser des éléments aléatoires est d'utiliser un générateur que l'on définit soi-même:

```{python}
seed = 12345  # Toujours être conscient qu'une graine existe
rng = np.random.default_rng(seed)  #
print(rng.random())  ##  un tirage uniforme sur [0,1]
print(rng.random(size=5))  ## cinq tirages uniformes sur [0,1]
print(rng.random(size=(3, 2)))  ## matrice 3x2, à entrées unif. sur [0,1]
```

Dans la suite on va voir comment générer d'autres lois à partir de la loi uniforme, mais il est clair que les logiciels modernes propose un large éventail de distribution classique (gaussienne, exponentielle, etc.).
Une liste exhaustive est donnée [ici](https://numpy.org/doc/stable/reference/random/generator.html#distributions) pour `numpy`.

::: {.callout-note appearance="simple"}
## Pour aller plus loin
Une excellent discussion sur les bonnes pratiques aléatoires en `numpy`, et l'usage de `np.random.default_rng` est donnée dans ce [blog post d'Albert Thomas](https://albertcthomas.github.io/good-practices-random-number-generators/).
:::



### Propriété de la loi uniforme
On verra souvent apparaître la variable aléatoire $1-U$ où $U \sim \mathcal{U}([0,1])$. Il se trouve que $1-U$ suit aussi une loi uniforme sur $[0,1]$ comme le montre le calcul de sa fonction de répartition. Ainsi pour tout $x \in [0,1]$ on obtient
$$
\begin{align*}
\mathbb{P}(1-U \leq x) & = \mathbb{P}(U \geq 1-x),\\
                       & = 1-(1-x), \\
                       & = x\,.
\end{align*}
$$
On peut démontrer facilement la même relation pour $x<0$ et $x>1$, d'où le résultat.


## Méthode d'inversion


L'idée de la méthode d'inversion repose sur le résultat suivant : si $F$ est une fonction de répartition bijective et $U \sim\mathcal{U}([0,1])$, alors la variable aléatoire $F^{-1}(U)$ a pour fonction de répartition $F$. C'est une conséquence de la suite d'égalités :
$$
\begin{align}
  \mathbb{P}( F^{-1}(U) \leq x ) & = \mathbb{P}( U \leq F(x) ) \\ 
                                 & = F(x)\,,
\end{align}
$${#eq-methode_inversion}

où la deuxième égalité résulte de la bijectivité de $F$.
Ainsi, si $F$ est facilement inversible, on peut simuler une variable aléatoire $X$ de loi $F$ en simulant une variable aléatoire uniforme $U$ et en posant $X = F^{-1}(U)$.


Malheureusement, la fonction $F$ n'est pas toujours inversible (penser aux lois discrètes) c'est donc pourquoi on utilise l'inverse l'inverse généralisée ou fonction quantile introduite dans la section [Notations](notations.qmd):
<!-- @def-quantile: -->

$$
  F^\leftarrow(p)=  \inf\{ x \in \mathbb{R} \colon F(x)\geq p\} \enspace.
$$


**Interprétation:** Définir l'inverse d'une fonction de répartition $F$ revient à résoudre l'équation $F(x) = \alpha$ d'inconnue $x$ pour un $\alpha$ fixé.
Si $F$ n'est pas bijective, deux problèmes apparaissent :

- l'équation n'a aucune solution ce qui revient à dire que $F$ n'est pas surjectif (graphiquement, $F$ présente des sauts) ;
- l'équation a plusieurs solutions ce qui revient à dire que $F$ n'est pas injective (graphiquement cela se matérialise par un plateau à la hauteur $\alpha$). Un exemple classique est celui où $F$ est la fonction de répartition d'une variable aléatoire discrète.

Le passage à l'inéquation $F(x) \geq u$ permet de contourner la non-surjectivité : on ne regarde non plus les droites horizontales $y=u$ mais la région $\{y \geq \alpha\}$. Le choix de l'$\inf$ dans la définition de $F^{\leftarrow}$ permet de contourner la non-injectivité : vu qu'il y a possiblement plusieurs $x$ tels que $F(x) \geq u$, on choisit le "premier". Ces considérations sont illustrées en Figure XXX TODO.



```{python}
#| echo: false
#| label: fig-3-quantiles
from scipy import stats
import plotly.graph_objects as go
# import matplotlib.pyplot as plt
# plt.rcParams['text.usetex'] = True
from plotly.subplots import make_subplots

def keep_no_param_distribution():
    distributions = stats._continuous_distns._distn_names
    distributions_0 = [name for name in distributions if not getattr(stats, name).shapes]
    distributions_0_val = [getattr(stats.distributions, string) for string in distributions_0]
    distributions_0_dict = dict(zip(distributions_0, distributions_0_val))
    return distributions_0_dict

def keep_no_param_distribution_disc():
    distributions = stats._discrete_distns._distn_names
    distributions_0 = [name for name in distributions if not getattr(stats, name).shapes or len(getattr(stats, name).shapes) in [1, 2]]
    distributions_0_val = [getattr(stats.distributions, string) for string in distributions_0]
    distributions_0_dict = dict(zip(distributions_0, distributions_0_val))
    return distributions_0_dict

def cdf_tool(x, dtype='int64'):
    y = np.zeros(2*(len(x)), dtype=dtype)
    y[::2]=x
    y[1::2]=x
    return y[1::], y[:-1], y


def pmf_tool(x, dtype='int64'):
    y = np.zeros(2*(len(x)), dtype=dtype)
    y[::2]=x
    return y[1::], y[:-1], y


def insert_nones(my_list):
    for i, val in enumerate(my_list):
        if i % 3 == 2:
            my_list.insert(i, None)
    return my_list

x = np.linspace(-5, 5, num=300)
alpha = 0.75
mu = 0.5
fig = make_subplots(
            rows=1,
            cols=3,
            horizontal_spacing=0.15,
            subplot_titles=(
            "solution unique",
            "pas de solution",
            "infinité de solutions",
            ),
        )

fig.update_layout(
    title=go.layout.Title(
        text="Cas F(x)=u : ",
        x=0)
    )
# Quantile plot
color_blue = "rgb(66, 139, 202)"
fig.update_layout(autosize=True, height=340,
             showlegend=False,
            template="simple_white",
        )

for i, name_distrib in enumerate(['norm', 'poisson', 'geom']):
    if name_distrib == 'norm':
        distributions_0_dict = keep_no_param_distribution()
        distribution = distributions_0_dict[name_distrib]

        cdf_data = distribution.cdf(x)
        q_alpha = distribution.ppf(alpha)
        # Cdf part
        fig.add_trace(
            go.Scatter(
                x=x, y=cdf_data, mode="lines", marker={"color": "black"}, name="F", showlegend=True
            ),
            row=1,
            col=i+1,
        )

    else:
        distributions_0_dict = keep_no_param_distribution_disc()
        distribution = distributions_0_dict[name_distrib]
        q_alpha = distribution.ppf(alpha, mu)
        x_int = np.arange(np.floor(x.min()), np.ceil(x.max()))

        cdf_data = distribution.cdf(x_int, mu)
        pmf_data = distribution.pmf(x_int, mu)
        # Quantile plot
        support = pmf_data.nonzero()[0]

        new_x, new_y, new_z = cdf_tool(support)
        _, _, new_pmf = pmf_tool(support)

                # Cdf part
        fig.add_trace(
            go.Scatter(
                x=x_int[support], y=cdf_data[support],
                mode="markers", marker={"color": "black"}
            ),
            row=1,
            col=i+1,
        )
        fig.add_trace(
            go.Scatter(
                x=insert_nones(list(np.append(np.insert(x_int[new_x], 0, [x_int[0], x_int[new_x[0]]]),x_int[-1]))),
                y=insert_nones(list(np.append(np.insert(cdf_data[new_y], 0, [0,0]), cdf_data[-1]))),
                mode="lines",
                line=dict(color="black")
            ),
            row=1,
            col=i+1
        )


    # fig.add_trace(go.Scatter(x=x, y=cdf_data, mode="lines", line=dict(color="black"), name="CDF", showlegend=False), row=1,col=i+1)


    fig.add_trace(go.Scatter(x=[q_alpha, q_alpha], y=[0, alpha], mode="lines", line=dict(color=color_blue, dash="dash"), showlegend=False), row=1,col=i+1)

    fig.add_trace(go.Scatter(x=[x[0], q_alpha], y=[alpha, alpha], mode="lines", line=dict(color=color_blue, dash="dash"), showlegend=False), row=1,col=i+1)

    fig.add_trace(go.Scatter(x=[q_alpha], y=[alpha], mode="markers", marker=dict(color=color_blue, symbol="x", size=8), name="Quantile", showlegend=False), row=1,col=i+1)

    fig.add_trace(go.Scatter(x=[x[0] + x.ptp() / 12], y=[alpha + 0.05], text="u", mode="text", showlegend=False, textfont_color=color_blue), row=1,col=i+1)

    # fig.add_trace(go.Scatter(x=[q_alpha + 0.1], y=[0.03], text="F <sup>&#x2190; </sup>(u)", mode="text", showlegend=False), row=1,col=i+1)
        # Axes ranges
    # fig.update_yaxes(range=[0, 1.], row=1, col=i+1)
    # fig.update_xaxes(matches="x1", row=2, col=1)
    # Axes ranges
    fig.update_yaxes(range=[0, 1.], row=1, col=i+1)
    fig.update_xaxes(range=[x.min(), x.max()], row=1, col=i+1)

    # fig.update_yaxes(matches="x6", row=1, col=1)

    # fig.update_yaxes(range=[0, 1.], row=2, col=1)
    # fig.update_xaxes(matches="x1", row=2, col=1)

    # fig.update_yaxes(rangemode="tozero", row=3, col=2)
    # fig.update_xaxes(range=[x[0], x[-1]], row=3, col=2)

fig.update_yaxes(matches="y1", row=1, col=2)
fig.update_yaxes(matches="y1", row=1, col=3)

fig.update_xaxes(matches="x1", row=1, col=2)
fig.update_xaxes(matches="x1", row=1, col=3)

fig.show()

# alpha = 0.75
# mu = 0.5
# # Create the subplots
# fig, axs = plt.subplots(1, 3)

# # Quantile plot
# color_blue = (66 / 256, 139 / 256, 202 / 256)
# for i, name_distrib in enumerate(['norm', 'poisson', 'geom']):
#     if name_distrib=='norm':
#         distributions_0_dict = keep_no_param_distribution()
#         distribution = distributions_0_dict[name_distrib]

#         cdf_data = distribution.cdf(x)
#         q_alpha = distribution.ppf(alpha)
#     else:
#         distributions_0_dict = keep_no_param_distribution_disc()
#         distribution = distributions_0_dict[name_distrib]
#         q_alpha = distribution.ppf(alpha, mu)
#         cdf_data = distribution.cdf(x, mu)
#         pmf_data = distribution.pmf(x, mu)
#     distribution = distributions_0_dict[name_distrib]



#     axs[i].plot(x, cdf_data, color="black", lw=3, zorder=1)
#     axs[i].plot([q_alpha,q_alpha], [0,alpha], color=color_blue, linestyle="--", zorder=2)
#     axs[i].plot([x[0], q_alpha], [alpha, alpha], color=color_blue, linestyle="--", zorder=2)
#     axs[i].scatter(q_alpha, alpha, color=color_blue, marker="o", s=100, zorder=2)
#     axs[i].set_ylim(0, 1)
#     axs[i].set_xlim(x[0], x[-1])
#     axs[i].text(x[0]+x.ptp()/100, alpha+0.03, r'$u$', fontsize=18, color=color_blue)
#     axs[i].text(q_alpha+0.1, 0.03, r'$F^\leftarrow(u)$', fontsize=18, color=color_blue)

# # Set subplot titles
# axs[0].set_title(r"Cas $F(x)=u$ : solution unique (cas Gaussien)")
# axs[1].set_title(r"Cas $F(x)=u$ : n'ayant pas de solution (cas )")
# axs[2].set_title(r"Cas $F(x)=u$ : solution unique (cas Gaussien)")

# Remove ticks from the second and third subplots


# Adjust spacing between subplots
# plt.subplots_adjust(wspace=0.5)

# Show the plot
# plt.show()

# alpha=0.3
# distribution = distributions_0_dict['norm']
# cdf_data = distribution.cdf(x, loc=0, scale=1)
# q_alpha = distribution.ppf(alpha, loc=0, scale=1)

# fig = make_subplots(
#             rows=1,
#             cols=3,
#             vertical_spacing=0.1,
#             horizontal_spacing=0.15,
#             subplot_titles=(
#                 "Cas $F(x)=u$ ayant une solution unique (cas Gaussien)",
#                 "Cas $F(x)=u$ n'ayant pas de solution (cas )",
#                 "Cas $F(x)=u$ ayant une infinité de solution (cas )",
#             ),
#             column_widths=[0.3, 0.3, 0.3],
# )

# fig.update_layout(
#     template="simple_white",
#     showlegend=False,
# )

# fig.update_layout(autosize=True, height=700)
# # Quantile plot
# fig.add_trace(
#       go.Scatter(
#           x=x, y=cdf_data, mode="lines", marker={"color": "black"}
#       ),
#       row=1,
#       col=1,
#   )

# # fig.add_trace(
# #     go.Scatter(
# #         mode='lines',
# #         line=dict(color="rgb(66, 139, 202)", width=3),
# #         x=x,
# #         y=scipy.stats.uniform.cdf(x),
# #         name=r'$F_U$'
# #     )
# # )

# fig.add_trace(
#     go.Scatter(
#         x=[x[0], q_alpha],
#         y=[alpha, alpha],
#         mode="lines",
#         line=dict(dash="dash", color="rgb(66, 139, 202)")
#     ),
#     row=1,
#     col=1
# )
# fig.add_trace(
#     go.Scatter(
#         x=[q_alpha, q_alpha],
#         y=[0, alpha],
#         mode="lines",
#         line=dict(dash="dash", color="rgb(66, 139, 202)")
#     ),
#     row=1,
#     col=1
# )
# fig.add_trace(
#     go.Scatter(
#         x=[q_alpha],
#         y=[alpha],
#         mode="markers",
#         marker={"color": "rgb(66, 139, 202)"},
#         marker_symbol="circle",
#         marker_size=15,
#     ),
#     row=1,
#     col=1,
# )
# fig.update_yaxes(range=[0, 1.], row=1, col=1)


```

**Remarques additionnelles**:

- La fonction $F$ étant croissante, la quantité $F^\leftarrow(u)$ correspond au premier instant où $F$ dépasse $\alpha$.
  Si $F$ est bijective (ce qui équivaut dans ce cas à strictement croissante et injective), alors $F^\leftarrow = F^{-1}$.
- La fonction $F^\leftarrow$ n'est rien d'autre que la fonction quantile : si $0 < \alpha < 1$, $q_{1-\alpha} = F^\leftarrow(1-\alpha)$ est le quantile d'ordre $(1-\alpha)$ de $F$. Par exemple, $F^\leftarrow(1/2)$ correspond à la médiane.
- Notons que si $u=0$, on peut alors naturellement poser $F^{\leftarrow}(0) = -\infty$. De même, avec la convention la convention $\inf \emptyset = +\infty$, on peut alors étendre la définition de $F^\leftarrow$ à $u=1$ (mais $F^\leftarrow(1)$ n'est pas toujours égal à $\infty$, voir les exemples ci-dessous).



::: {#def-inversion_discrete}
##  Loi à support fini

<br>

Soit $X$ une variable aléatoire discrète prenant uniquement les valeurs $x_1 < \dots < x_r$ avec probabilité $p_1, \dots, p_r$, et tel que $p_1 + \dots + p_r=1$.
On vérifie que pour tout $u \in ]0,1[$,
$$
		F^\leftarrow(u) =
		\begin{cases}
			x_1 & \text{si } 0 < u \leq p_1\,,                  \\
			x_2 & \text{si } p_1 < u \leq p_1+p_2\,,            \\
			    & \vdots                                        \\
			x_r & \text{si }  p_1 + \dots + p_{r-1} < u < 1\,.
		\end{cases}
$$

Sur cet exemple, on peut prolonger la définition de $F^\leftarrow$ à $u=1$ en posant $F^\leftarrow(1) = x_r$.
L'inverse généralisée se réécrit alors sous la forme
$$
		F^\leftarrow(u) = \sum_{k=1}^r x_k {1\hspace{-3.8pt} 1}_{p_1 + \dots + p_{k-1} < u \leq p_1 + \dots + p_k}\enspace,
$$
où on a posé $p_0=0$. Cette expression s'étend directement au cas où $X$ prend un nombre infini dénombrable de valeurs (la somme devient alors une série).
:::
XXX TODO: donner un example discret et montrer $F^\leftarrow$.


XXX TODO: show inverse usage using widget from first course and sampling randomly uniformly points in $[0,1]$ to get the one from the distributions at hand.










## Méthode de rejet

L'idée de la méthode de rejet est la suivante. On souhaite simuler une variable aléatoire $X$ de densité $f$, appelée **loi cible**, mais $f$ est trop compliquée pour que la simulation puisse se faire directement.
On dispose cependant d'une autre densité $g$ possédant les propriétés suivantes :

- on sait simuler $Y$ de loi $g$,
- il existe $m > 0$ tel que $f(x) \leq m \cdot g(x)$,
- on sait évaluer le **rapport d'acceptation** $r(x) = \frac{f(x)}{mg(x)}$.


Remarquons d'ores et déjà que la constante $m$ est nécessairement plus grande que $1$ car
$$
	1 = \int_\mathbb{R} f(x) \, \mathrm dx \leq m \int_\mathbb{R} g(x)\, \mathrm dx = m\,.
$$


L'idée est alors de considérer deux suites iid de variables aléatoires indépendantes entre elles :

- $(Y_n)_{n \geq 1}$ de loi $g$,
- $(U_n)_{n \geq 1}$ de loi uniforme sur $[0,1]$.

En pratique, $Y_n$ correspond à une proposition et $U_n$ permettra de décider si on accepte la proposition ou non. Si oui, alors on conserve $Y_n$, sinon on simule $Y_{n+1}$. Le rapport d'acceptation, c'est-à-dire la proportion de $Y_n$ acceptées, correspond à $r(x)$.


Autrement dit, pour simuler $X$ de densité $f$, il suffit de simuler $Y$ de densité $g$ et $U$ uniforme jusqu'à ce que $U \leq r(Y)$ (voir Figure ??? pour une illustration). La proposition suivante assure que cette méthode donne bien le résultat voulu.

:::: {#prp-rejet}

## Méthode de rejet

<br>

Soit $T = \inf \{n \geq 1 : U_n \leq r(Y_n)\}$ le premier instant où le tirage est accepté. Alors :

- $T$ suit une loi géométrique de paramètre $1/m$,
- la variable aléatoire $X = Y_T$ a pour densité $f$ et est indépendante de $T$.
::::



*Démonstration*:

Il s'agit d'étudier la loi du couple $(X,T)$. Pour $x \in \mathbb{R}$ et $n \in \mathbb{N}$, on écrit
$\mathbb{P}(X \leq x, T=n)= \mathbb{P}(U_1 > r(Y_1), \dots, U_{n-1} > r(Y_{n-1}), U_n \leq r(Y_n), Y_n \leq x).$
Les $n$ tirages étant iid, on obtient
$$
    \mathbb{P}(X \leq x, T=n) = \mathbb{P}(U_1 > r(Y_1))^{n-1} \mathbb{P}(U_n \leq r(Y_n), Y_n \leq x)\,.
$$

Concernant le premier terme, les variables aléatoires $Y_1$ et $U_1$ sont indépendantes donc leur loi jointe correspond au produit des densités :
$$\begin{align*}
		\mathbb{P}(U_1 > r(Y_1)
		 & = \mathbb{P}((U_1, Y_1) \in \{(u,y) \in \mathbb{R}^2 : u > r(y)\})                             \\
		 & = \int_{\mathbb{R}^2} {1\hspace{-3.8pt} 1}_{\{u > r(y)\}} ({1\hspace{-3.8pt} 1}_{[0,1]}(u) g(y)) \, \mathrm du \mathrm dy  \\
		 & = \int_\mathbb{R} \bigg( \int_0^1 {1\hspace{-3.8pt} 1}_{\{u > r(y)\}} \, \mathrm du\bigg) g(y)\, \mathrm d y \\
		 & =  \int_\mathbb{R} (1-r(y)) \, g(y)\, \mathrm d y\,,
	\end{align*}
$$
ce qui se réécrit, comme $f$ et $g$ sont des densités et que $r(y) = f(y)/(m \cdot g(y))$:
$$\begin{align*}
		\mathbb{P}(U_1 > r(Y_1))
		& = \int_\mathbb{R} g(y)\, \mathrm d y - \int_\mathbb{R} \dfrac{f(y)}{m}\, \mathrm dy \\
		& = 1 - \dfrac{1}{m}\,.
	\end{align*}
$$
Le deuxième terme se calcule de manière analogue :
$$
\begin{align*}
    \mathbb{P}(U_n \leq r(Y_n), Y_n \leq x)
        & = \int_{\mathbb{R}^2} {1\hspace{-3.8pt} 1}_{\{u \leq r(y)\}} {1\hspace{-3.8pt} 1}_{\{y \leq x\}} ({1\hspace{-3.8pt} 1}_{[0,1]}(u) g(y)) \, \mathrm du \mathrm dy       \\
        & = \int_\mathbb{R} \bigg( \int_0^1  {1\hspace{-3.8pt} 1}_{\{u \leq r(y)\}} \, \mathrm du\bigg) {1\hspace{-3.8pt} 1}_{\{y \leq x\}}  g(y)\, \mathrm d y\,,
\end{align*}
$$
c'est-à-dire
$$
\begin{align*}
        \mathbb{P}(U_n \leq r(Y_n), Y_n \leq x)
		& = \int_\mathbb{R} r(y) {1\hspace{-3.8pt} 1}_{\{y \leq x\}}  g(y)\, \mathrm d y \\
		& = \int_{-\infty}^x \dfrac{f(y)}{m}\, \mathrm d y \\
		& = \dfrac{F(x)}{m}\,,
\end{align*}
$$
où $F$ est la fonction de répartition de la loi de densité $f$. On peut ainsi conclure que
$$
    \mathbb{P}(X \leq x, T=n)
    =
    \bigg(1 - \dfrac{1}{m}\bigg)^{n-1} \dfrac{F(x)}{m}\,.
$$
Il ne reste plus qu'à étudier les lois marginales.
D'une part, par continuité monotone croissante,
$$
    \mathbb{P}(T=n)
    = \lim_{q \to \infty} \mathbb{P}(X \in ]-\infty, q], T=n)\,,
$$
ce qui donne
$$
    \mathbb{P}(T=n)
    = \lim_{q \to \infty} \bigg(1 - \dfrac{1}{m}\bigg)^{n-1} \dfrac{F(q)}{m}
    = \bigg(1 - \dfrac{1}{m}\bigg)^{n-1} \dfrac{1}{m}\,.
$$
On en déduit que $T$ suit une loi géométrique de paramètre $1/m$. D'autre part, par $\sigma$-additivité,
$$
    \mathbb{P}(X \leq x)
    = \mathbb{P}(X \leq x, T \in \mathbb{N}^*)
    = \sum_{n=1}^\infty \mathbb{P}(X \leq x, T=n)\,,
$$
ce qui donne
$$
\begin{align*}
    \mathbb{P}(X \leq x)
    & = \sum_{n=1}^\infty \bigg(1 - \dfrac{1}{m}\bigg)^{n-1} \dfrac{F(x)}{m}\\
    & = \dfrac{1}{1-(1-1/m)} \dfrac{F(x)}{m}\\
    & = F(x)\,,
\end{align*}
$$
ce qui prouve que $X$ a pour loi $F$.

Enfin, la loi du couple $(X,T)$ est égale au produit des lois
$$
    \mathbb{P}(X \leq x, T=n)
    = \bigg(1 - \dfrac{1}{m}\bigg)^{n-1} \dfrac{F(x)}{m}
    = \mathbb{P}(T=n) \mathbb{P}(X \leq x)\,,
$$
<div class="container"> 
<div class="div1">ce qui prouve l'indépendance de $X$ et $T$.</div> 
<div class="div-remaining">□</div> 
</div> 




### Bibliographie et pour aller plus loin

- [Generating Random Floating-Point Numbers by Dividing Integers: a Case Study](https://hal.science/hal-02427338/document) par Frédéric Goualard
- [Generating Pseudo-random Floating-Point Values](https://allendowney.com/research/rand/downey07randfloat.pdf) par Allen Downey.
